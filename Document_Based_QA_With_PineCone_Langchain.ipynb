{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7d5073",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d22db25",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured[all-docs]\n",
      "  Obtaining dependency information for unstructured[all-docs] from https://files.pythonhosted.org/packages/e3/97/478e5f01e8922acc140ee35adde4c5e6861f7a693fe57daafe53947e6602/unstructured-0.10.8-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.10.8-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: chardet in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (4.0.0)\n",
      "Requirement already satisfied: filetype in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (1.2.0)\n",
      "Collecting python-magic (from unstructured[all-docs])\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: lxml in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (4.9.1)\n",
      "Requirement already satisfied: nltk in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (3.5)\n",
      "Requirement already satisfied: tabulate in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (0.8.10)\n",
      "Requirement already satisfied: requests in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (4.12.2)\n",
      "Requirement already satisfied: emoji in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (2.4.0)\n",
      "Requirement already satisfied: pandas in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (1.5.3)\n",
      "Collecting python-pptx (from unstructured[all-docs])\n",
      "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m542.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdfminer.six (from unstructured[all-docs])\n",
      "  Using cached pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: markdown in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (3.4.1)\n",
      "Requirement already satisfied: Pillow<10 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (7.2.0)\n",
      "Collecting xlrd (from unstructured[all-docs])\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m529.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting ebooklib (from unstructured[all-docs])\n",
      "  Downloading EbookLib-0.18.tar.gz (115 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m339.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-docx (from unstructured[all-docs])\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m255.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting msg-parser (from unstructured[all-docs])\n",
      "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m711.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pypandoc (from unstructured[all-docs])\n",
      "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: openpyxl in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured[all-docs]) (3.0.10)\n",
      "Collecting pdf2image (from unstructured[all-docs])\n",
      "  Downloading pdf2image-1.16.3-py3-none-any.whl (11 kB)\n",
      "Collecting unstructured-inference (from unstructured[all-docs])\n",
      "  Obtaining dependency information for unstructured-inference from https://files.pythonhosted.org/packages/f8/18/6f4bb4901004b3e36ecc7b2e1e031a3de3779fea7aa15459e30d784bef1e/unstructured_inference-0.5.17-py3-none-any.whl.metadata\n",
      "  Downloading unstructured_inference-0.5.17-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->unstructured[all-docs]) (2.4)\n",
      "Requirement already satisfied: six in /home/mohammed_shaneeb/.local/lib/python3.9/site-packages (from ebooklib->unstructured[all-docs]) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/mohammed_shaneeb/.local/lib/python3.9/site-packages (from markdown->unstructured[all-docs]) (6.0.0)\n",
      "Collecting olefile>=0.46 (from msg-parser->unstructured[all-docs])\n",
      "  Downloading olefile-0.46.zip (112 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from nltk->unstructured[all-docs]) (8.1.6)\n",
      "Requirement already satisfied: joblib in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from nltk->unstructured[all-docs]) (1.2.0)\n",
      "Requirement already satisfied: regex in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from nltk->unstructured[all-docs]) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from nltk->unstructured[all-docs]) (4.65.0)\n",
      "Requirement already satisfied: et_xmlfile in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from openpyxl->unstructured[all-docs]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from pandas->unstructured[all-docs]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from pandas->unstructured[all-docs]) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from pandas->unstructured[all-docs]) (1.23.5)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from pdfminer.six->unstructured[all-docs]) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from pdfminer.six->unstructured[all-docs]) (41.0.2)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured[all-docs])\n",
      "  Obtaining dependency information for XlsxWriter>=0.5.7 from https://files.pythonhosted.org/packages/37/94/25d3ec8587974de7ebd790232aa3155abfe44ed23df7ccaa4645977a1cbe/XlsxWriter-3.1.2-py3-none-any.whl.metadata\n",
      "  Downloading XlsxWriter-3.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from requests->unstructured[all-docs]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from requests->unstructured[all-docs]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from requests->unstructured[all-docs]) (2023.7.22)\n",
      "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference->unstructured[all-docs])\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: python-multipart in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured-inference->unstructured[all-docs]) (0.0.6)\n",
      "Requirement already satisfied: huggingface-hub in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured-inference->unstructured[all-docs]) (0.15.1)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured-inference->unstructured[all-docs]) (4.7.0.72)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime (from unstructured-inference->unstructured[all-docs])\n",
      "  Obtaining dependency information for onnxruntime from https://files.pythonhosted.org/packages/50/d5/f156d808c9cc59e7a8b87843a5313719d01eec7d3b17ca3f6b6f0fbee0f0/onnxruntime-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading onnxruntime-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from unstructured-inference->unstructured[all-docs]) (4.29.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (1.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mohammed_shaneeb/.local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown->unstructured[all-docs]) (3.15.0)\n",
      "Requirement already satisfied: filelock in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference->unstructured[all-docs]) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mohammed_shaneeb/.local/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference->unstructured[all-docs]) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference->unstructured[all-docs]) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference->unstructured[all-docs]) (0.13.2)\n",
      "Requirement already satisfied: fsspec in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from huggingface-hub->unstructured-inference->unstructured[all-docs]) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from huggingface-hub->unstructured-inference->unstructured[all-docs]) (4.7.1)\n",
      "Requirement already satisfied: scipy in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (1.10.1)\n",
      "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Obtaining dependency information for pdfplumber from https://files.pythonhosted.org/packages/c1/f9/1a41afffe5e7a98ab9b6a6dd3dab9d99b677fae2536f676397c4506f6554/pdfplumber-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading pdfplumber-0.10.2-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: torch in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.15.2a0)\n",
      "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Obtaining dependency information for effdet from https://files.pythonhosted.org/packages/9c/13/563119fe0af82aca5a3b89399c435953072c39515c2e818eb82793955c3b/effdet-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting coloredlogs (from onnxruntime->unstructured-inference->unstructured[all-docs])\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from onnxruntime->unstructured-inference->unstructured[all-docs]) (23.5.9)\n",
      "Requirement already satisfied: protobuf in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from onnxruntime->unstructured-inference->unstructured[all-docs]) (4.21.12)\n",
      "Requirement already satisfied: sympy in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from onnxruntime->unstructured-inference->unstructured[all-docs]) (1.11.1)\n",
      "Requirement already satisfied: pycparser in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]) (2.21)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->unstructured-inference->unstructured[all-docs])\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Obtaining dependency information for timm>=0.9.2 from https://files.pythonhosted.org/packages/14/38/05b37b7692e521bbada22593ac3b6d7ba3f378d56b5d1ccb322a541bbb6e/timm-0.9.5-py3-none-any.whl.metadata\n",
      "  Downloading timm-0.9.5-py3-none-any.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycocotools>=2.0.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Obtaining dependency information for pycocotools>=2.0.2 from https://files.pythonhosted.org/packages/fe/83/ae272705f1b2e4efe0cd2e7e2de0233386ed578a2356c6409e3db268e2db/pycocotools-2.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pycocotools-2.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting omegaconf>=2.0 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.1.2)\n",
      "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting Pillow<10 (from unstructured[all-docs])\n",
      "  Using cached Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Obtaining dependency information for pypdfium2>=4.18.0 from https://files.pythonhosted.org/packages/cc/bd/2052075f453728535cc782bcf0fd3794149c516caf2de240060f52308c4b/pypdfium2-4.19.0-py3-none-manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading pypdfium2-4.19.0-py3-none-manylinux_2_17_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from sympy->onnxruntime->unstructured-inference->unstructured[all-docs]) (1.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs])\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.7.1)\n",
      "Requirement already satisfied: safetensors in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from timm>=0.9.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference->unstructured[all-docs]) (5.2.0)\n",
      "Downloading unstructured-0.10.8-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_inference-0.5.17-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m954.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdfplumber-0.10.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.5/47.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycocotools-2.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.1/435.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdfium2-4.19.0-py3-none-manylinux_2_17_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m538.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ebooklib, python-docx, python-pptx, olefile, iopath, antlr4-python3-runtime\n",
      "  Building wheel for ebooklib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ebooklib: filename=EbookLib-0.18-py3-none-any.whl size=38777 sha256=94cbb36df75d2b8926fd8efa379de4c56becf1214af79f8dba8a8d9d5f72c0d6\n",
      "  Stored in directory: /home/mohammed_shaneeb/.cache/pip/wheels/47/3a/ec/289c2f96d54695a17d260684be304d20a8d0bf50b08b75862e\n",
      "  Building wheel for python-docx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184490 sha256=15bd82d2118310ea7d36074f952545cd0b617deb11e258ed6186ef9dfb92a98e\n",
      "  Stored in directory: /home/mohammed_shaneeb/.cache/pip/wheels/83/8b/7c/09ae60c42c7ba4ed2dddaf2b8b9186cb105255856d6ed3dba5\n",
      "  Building wheel for python-pptx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470935 sha256=9013aeb4be477f72a7a27d19ccf95e91a89adbf35b1c2336692aa9c3c9bf0894\n",
      "  Stored in directory: /home/mohammed_shaneeb/.cache/pip/wheels/0e/4a/ed/9653bc799915f52dce3f04d14946fbd85cce9c3cdedc9cfa71\n",
      "  Building wheel for olefile (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=80b426c55e9ea907613677666df0d1aaf16813b511c52bfaced0bebcac0f7b77\n",
      "  Stored in directory: /home/mohammed_shaneeb/.cache/pip/wheels/64/b8/ba/ebba30390fbd997074f35e42a842ce3fd933213cac8753414e\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=cf33978cd93e3e3867f0dbb9918a18220c7d6dd36c4a8286292584dc88586027\n",
      "  Stored in directory: /home/mohammed_shaneeb/.cache/pip/wheels/c1/13/6d/441d8f2af76ee6d2a3e67eebb1d0c556fefcee0a8b32266a8e\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=24e5f6e795ed185dc4ae806abc3b924ab34454b29c60ec5434147cb1421e0049\n",
      "  Stored in directory: /home/mohammed_shaneeb/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "Successfully built ebooklib python-docx python-pptx olefile iopath antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, XlsxWriter, xlrd, python-magic, python-docx, pypdfium2, pypandoc, portalocker, Pillow, omegaconf, olefile, humanfriendly, ebooklib, unstructured, python-pptx, pytesseract, pdf2image, msg-parser, iopath, coloredlogs, pycocotools, pdfminer.six, onnxruntime, timm, pdfplumber, layoutparser, effdet, unstructured-inference\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 7.2.0\n",
      "    Uninstalling Pillow-7.2.0:\n",
      "      Successfully uninstalled Pillow-7.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "label-studio-converter 0.0.30 requires Pillow<8,>=7, but you have pillow 9.5.0 which is incompatible.\n",
      "pandasai 0.8.2 requires ipython<9.0.0,>=8.13.1, but you have ipython 8.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-9.4.0 XlsxWriter-3.1.2 antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 ebooklib-0.18 effdet-0.4.1 humanfriendly-10.0 iopath-0.1.10 layoutparser-0.3.4 msg-parser-1.2.0 olefile-0.46 omegaconf-2.3.0 onnxruntime-1.15.1 pdf2image-1.16.3 pdfminer.six-20221105 pdfplumber-0.10.2 portalocker-2.7.0 pycocotools-2.0.7 pypandoc-1.11 pypdfium2-4.19.0 pytesseract-0.3.10 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.21 timm-0.9.5 unstructured-0.10.8 unstructured-inference-0.5.17 xlrd-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unstructured[all-docs]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a1fd1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for mohammed_shaneeb: \n"
     ]
    }
   ],
   "source": [
    "!apt-get install poppler-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6994aa9",
   "metadata": {},
   "source": [
    "## OPENAI configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bff1d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa62dec",
   "metadata": {},
   "source": [
    "## Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1bc0c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "directory ='data'\n",
    "\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return  documents\n",
    "\n",
    "documents = load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8dc620",
   "metadata": {},
   "source": [
    "## Splitting Texts into Chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "378f74e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_doc(documents,chunk_size=1000,chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "docs = split_doc(documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3829d8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='i\\n\\nAbout the Tutorial\\n\\nToday’s Artificial Intelligence (AI) has far surpassed the hype of blockchain and quantum computing. The developers now take advantage of this in creating new Machine Learning models and to re-train the existing models for better performance and results.\\n\\nThis tutorial will give an introduction to machine learning and its implementation in Artificial Intelligence.\\n\\nAudience\\n\\nThis tutorial has been prepared for professionals aspiring to learn the complete picture of machine learning and artificial intelligence.\\n\\nThis tutorial caters the learning needs of both the novice learners and experts, to help them understand the concepts and implementation of artificial intelligence.\\n\\nPrerequisites\\n\\nThe learners of this tutorial are expected to know the basics of Python programming. Besides, they need to have a solid understanding of computer programing and fundamentals.' metadata={'source': 'data/machine_learning_tutorial.pdf'}\n",
      "page_content='i\\n\\nAbout the Tutorial\\n\\nToday’s Artificial Intelligence (AI) has far surpassed the hype of blockchain and quantum computing. The developers now take advantage of this in creating new Machine Learning models and to re-train the existing models for better performance and results.\\n\\nThis tutorial will give an introduction to machine learning and its implementation in Artificial Intelligence.\\n\\nAudience\\n\\nThis tutorial has been prepared for professionals aspiring to learn the complete picture of machine learning and artificial intelligence.\\n\\nThis tutorial caters the learning needs of both the novice learners and experts, to help them understand the concepts and implementation of artificial intelligence.\\n\\nPrerequisites\\n\\nThe learners of this tutorial are expected to know the basics of Python programming. Besides, they need to have a solid understanding of computer programing and fundamentals.' metadata={'source': 'data/machine_learning_tutorial.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959371ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "\n",
      "About the Tutorial\n",
      "\n",
      "Today’s Artificial Intelligence (AI) has far surpassed the hype of blockchain and quantum computing. The developers now take advantage of this in creating new Machine Learning models and to re-train the existing models for better performance and results.\n",
      "\n",
      "This tutorial will give an introduction to machine learning and its implementation in Artificial Intelligence.\n",
      "\n",
      "Audience\n",
      "\n",
      "This tutorial has been prepared for professionals aspiring to learn the complete picture of machine learning and artificial intelligence.\n",
      "\n",
      "This tutorial caters the learning needs of both the novice learners and experts, to help them understand the concepts and implementation of artificial intelligence.\n",
      "\n",
      "Prerequisites\n",
      "\n",
      "The learners of this tutorial are expected to know the basics of Python programming. Besides, they need to have a solid understanding of computer programing and fundamentals.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25350f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally, when it comes to the development of machine learning models of your own, you looked at the choices of various development languages, IDEs and Platforms. Next thing that you need to do is start learning and practicing each machine learning technique. The subject is vast, it means that there is width, but if you consider the depth, each topic can be learned in a few hours. Each topic is independent of each other. You need to take into consideration one topic at a time, learn it, practice it and implement the algorithm/s in it using a language choice of yours. This is the best way to start studying Machine Learning. Practicing one topic at a time, very soon you would acquire the width that is eventually required of a Machine Learning expert.\n",
      "\n",
      "Good Luck!\n",
      "\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(docs[52].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce69b281",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53ce0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd67a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "[-0.012789793312549591, -0.01759009249508381, -0.00378015311434865, -0.009547775611281395, -0.02362513169646263]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-search-ada-doc-001\")\n",
    "text = \"Mohammed Shaneeb\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "print(len(query_result))\n",
    "print(query_result[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5497ae74",
   "metadata": {},
   "source": [
    "## Vecotor DB PineCone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "787ae309",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone-client -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a3f2755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/mohammed_shaneeb/anaconda3/lib/python3.9/site-packages (4.65.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7cda228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "PineCone_API_KEY = os.environ.get('PineCone_API_KEY')\n",
    "pinecone.init(\n",
    "    api_key = PineCone_API_KEY,\n",
    "    environment = \"gcp-starter\"\n",
    ")\n",
    "index_name = 'langchain-qa'\n",
    "\n",
    "index = Pinecone.from_documents(docs,embeddings,index_name=index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426dc16d",
   "metadata": {},
   "source": [
    "## Get Similar Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edcd803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs(query,k=2,score=False):\n",
    "    if score:\n",
    "        similar_docs = index.similarity_search_with_score(query,k=k)\n",
    "    else:\n",
    "        similar_docs = index.similarity_search(query,k)\n",
    "    return similar_docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ae43fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Why this is called a black-box approach is that you do not know why the network came up with a certain result. You do not know how the network concluded that it is a dog? Now consider a banking application where the bank wants to decide the creditworthiness of a client. The network will definitely provide you an answer to this question. However, will you be able to justify it to a client? Banks need to explain it to their customers why the loan is not sanctioned?\\n\\n23\\n\\nMachine Learning\\n\\nDuration of Development\\n\\nThe process of training a neural network is depicted in the diagram below:\\n\\nYou first define the problem that you want to solve, create a specification for it, decide on the input features, design a network, deploy it and test the output. If the output is not as expected, take this as a feedback to restructure your network. This is an iterative process and may require several iterations until the time network is fully trained to produce desired outputs.\\n\\nAmount of Data', metadata={'source': 'data/machine_learning_tutorial.pdf'}),\n",
       "  0.691587448),\n",
       " (Document(page_content='k-means clustering\\n\\nThe 2000 and 2004 Presidential elections in the United States were close — very close. The largest percentage of the popular vote that any candidate received was 50.7% and the lowest was 47.9%. If a percentage of the voters were to have switched sides, the outcome of the election would have been different. There are small groups of voters who, when properly appealed to, will switch sides. These groups may not be huge, but with such close races, they may be big enough to change the outcome of the election. How do you find these groups of people? How do you appeal to them with a limited budget? The answer is clustering.\\n\\nLet us understand how it is done.\\n\\nFirst, you collect information on people either with or without their consent: any sort of information that might give some clue about what is important to them and what will influence how they vote.\\n\\nThen you put this information into some sort of clustering algorithm.\\n\\n17\\n\\nMachine Learning', metadata={'source': 'data/machine_learning_tutorial.pdf'}),\n",
       "  0.67936492),\n",
       " (Document(page_content='Speech Recognition: Another interesting application of Deep Learning is speech recognition. All of us use several mobile apps today that are capable of recognizing our speech. Apple’s Siri, Amazon’s Alexa, Microsoft’s Cortena and Google’s Assistant – all these use deep learning techniques.\\n\\nMobile Apps: We use several web-based and mobile apps for organizing our photos. Face detection, face ID, face tagging, identifying objects in an image – all these use deep learning.\\n\\nUntapped Opportunities of Deep Learning\\n\\nAfter looking at the great success deep learning applications have achieved in many domains, people started exploring other domains where machine learning was not so far applied. There are several domains in which deep learning techniques are successfully applied and there are many other domains which can be exploited. Some of these are discussed here:\\n\\nAgriculture is one such industry where people can apply deep learning techniques\\n\\nto improve the crop yield.', metadata={'source': 'data/machine_learning_tutorial.pdf'}),\n",
       "  0.677491426),\n",
       " (Document(page_content='Table of Contents\\n\\nAbout the Tutorial ................................................................................................................................ i\\n\\nAudience ............................................................................................................................................... i\\n\\nPrerequisites ......................................................................................................................................... i\\n\\nCopyright & Disclaimer ......................................................................................................................... i\\n\\nTable of Contents ................................................................................................................................. ii\\n\\n1. MACHINE LEARNING – INTRODUCTION ............................................................................ 1', metadata={'source': 'data/machine_learning_tutorial.pdf'}),\n",
       "  0.676542401),\n",
       " (Document(page_content='17\\n\\nMachine Learning\\n\\nNext, for each cluster (it would be smart to choose the largest one first) you craft\\n\\na message that will appeal to these voters.\\n\\nFinally, you deliver the campaign and measure to see if it’s working.\\n\\nClustering is a type of unsupervised learning that automatically forms clusters of similar things. It is like automatic classification. You can cluster almost anything, and the more similar the items are in the cluster, the better the clusters are. In this chapter, we are going to study one type of clustering algorithm called k-means. It is called k-means because it finds ‘k’ unique clusters, and the center of each cluster is the mean of the values in that cluster.\\n\\nCluster Identification\\n\\nCluster identification tells an algorithm, “Here’s some data. Now group similar things together and tell me about those groups.” The key difference from classification is that in classification you know what you are looking for. While that is not the case in clustering.', metadata={'source': 'data/machine_learning_tutorial.pdf'}),\n",
       "  0.676403403)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What is scikit learn'\n",
    "similar_docs = get_similar_docs(query,score=True,k=5)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911b21a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce7e54e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7bd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e6893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
